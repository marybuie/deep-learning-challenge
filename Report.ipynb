{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 21: Deep learning/AlphabetSoup Charity challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis intends to evaluate the performance of a neural network model designed to predict the success of applications submitted to a ficitonal charity named Alphabet Soup. The model is trained on our dataset to identify factors which contribute to the success (or failure) of the ventures funded by Alphabet Soup. Ultimately, our goal is to provide Alphabet Soup with a tool that will help select applicants with the best chance of success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model Architecture and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model consists of an input layer, two hidden layers, and an output layer. The input layer has neurons equal to the number of features in the dataset. \n",
    "\n",
    "In the original model, we used two hidden layers with hidden neurons totaling 15, \"relu\" activation functions for the hidden layers, and an epoch of 10.\n",
    "\n",
    "The accuracy of this model was roughly 72%.\n",
    "\n",
    "In the first optimization, we changed the number of hidden neurons based on the formula: hidden neurons = (2/3 * input layer neurons) + 1. This yielded 48 hidden neurons which we distributed across three hidden layers.\n",
    "\n",
    "For the second optimization, we tripled the epoch time to 30.\n",
    "\n",
    "In the third optimization, we changed the 'relu' functions to 'elu'.\n",
    "\n",
    "Lastly, we combined all three optimizations.\n",
    "\n",
    "The results of all four optimizations were negligible.\n",
    "\n",
    "A visual model of the model's improvement over epochs was generated to ascertain whether any progress was being made. At 60 epochs, the model shows an improvement of about 1%, suggesting that, if the epochs were dramatically increased, accuracy would eventually improve to the target 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What variables are the target(s) for your model? ANSWER: \"IS_SUCCESSFUL\"\n",
    "2. What variable(s) are the features for your model? ANSWER: APPLICATION_TYPE, AFFILIATION, CLASSIFICATION, USE_CASE, ORGANIZATION, INCOME_AMT, SPECIAL_CONSIDERATIONS.\n",
    "3. What variable(s) should be removed from the input data because they are neither targets nor features? ANSWER: \"EIN\", \"NAME\"\n",
    "4. How many neurons, layers, and activation functions did you select for your neural network model, and why? ANSWER: First model has 2 layers with 10 and 5 neurons. Second model has 3 layers with 24, 16, and 8. I wanted 48 neurons to follow the advice that your hidden neurons should equal two-thirds of the neurons in your input layer plus the number of neurons in your output layer. I chose to add a layer and distribute them as proportionally as possible across each layer in an attempt to prevent overtraining, which I had struggled with in my earlier attempts (not included in final project).\n",
    "5. Were you able to achieve the target model performance? ANSWER: No, although I tried very hard. I also experimented with binning and with removing unnecessary columns at the beginning of this project, but those results yieled accuracies closer to 50%. All in all, I attempted roughly 12 optimizations. I decided to include 4 optimizations with the cleanest code possible in order to demonstrate the full force of my efforts.\n",
    "6. What steps did you take in your attempts to increase model performance? ANSWER: I added hidden neurons and input layers, increased epochs, changed activation functions (I tried 'tanh' in addition to 'elu,' but the results were disastrous), tried using RandomForestClassifier to locate and eliminate unimportant categories, all of it... I just couldn't get accuracy to rise above 72%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summation, the neural network model yielded a decent but not-good-enough accuracy score. Further optimization efforts might involve refining the data in earlier stages, before learning occurs. \n",
    "\n",
    "Cutoff values could possibly be altered in an advantageous manner.\n",
    "\n",
    "Random Forest could possibly be used to better effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
